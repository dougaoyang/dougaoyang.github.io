<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="这里记录了我在编程时遇到的一些问题，和解决这些问题的一些方法。还有一些是我对编程的一些看法观点，以及学习语言时的一些笔记和心得体会。"><title>核函数的概念以及在SVM上的应用 | DeepCode</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 4.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">核函数的概念以及在SVM上的应用</h1><a id="logo" href="/.">DeepCode</a><p class="description">高岸为谷，深谷为陵</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/tags/"><i class="fa fa-tag"> 标签</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">核函数的概念以及在SVM上的应用</h1><div class="post-meta">Feb 1, 2020<span> | </span><span class="category"><a href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.5k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 5</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><h2 id="高斯核函数"><a href="#高斯核函数" class="headerlink" title="高斯核函数"></a>高斯核函数</h2><p>激励函数中$\theta^Tx=\theta_0 + \theta_1x_1 + \theta_2x_2 + … + \theta_nx_n$</p>
<p>现在准备用新的特征值$f_1,f_2,…$ 来替换 $x_1,x_2,…$</p>
<p>将$f$定义为两个向量的相似度：</p>
<p>例如，有一个标记向量$l^{(i)}$，某个样本的特征向量$x$和其的相似度为：<br>$$ f_i = similarity(x, l^{(i)}) = exp(-\frac{|| x-l^{(i)} ||^2}{2\sigma^2})$$</p>
<p><em>PS：$|| x ||$ 是 x向量的范数。</em></p>
<p>该核函数又称之为<strong>高斯核函数（Gaussian Kernels）</strong>。</p>
<p>当$x$和$l^{(i)}$很相似时，$f_i \approx 1$；当两者差距很大时，$f_i \approx 0$。</p>
<p>高斯核函数中有个关键参数$\sigma$，它的大小决定了，该函数值的变化速度。当$\sigma$很小时，$f_i$的变化就会很快，两个向量一点细微的差距就会本放大。当$\sigma$变大时，则相反：</p>
<div style="display:flex;">
<img  src="/images/ml_28.jpg" alt="">
<img  src="/images/ml_29.jpg" alt="">
<img  src="/images/ml_30.jpg" alt="">
</div>

<p>举个例子，假设设计三个新的特征变量$f_1,f_2,f_3$：<br>当$\theta_0 + \theta_1f_1 + \theta_2f_2 + \theta_3f_3 \geq 0$时，通过预测函数$h(\theta)$预测为1。</p>
<p>我们假设$\theta_0=-0.5, \theta_1=1, \theta_2=1, \theta_3=0$</p>
<p>当样本x接近$l_1$时，$f_1 \approx 1$，$f_2 \approx 0$，$f_3 \approx 0$，可以得出上述表达式为$-0.5 + 1 + 0 + 0 = 0.5$，可以预测该样本的输出为1，以此类推，可以得出在标记向量$l_1,l_2$附近的向量即预测为1，远离的预测为0：</p>
<img width="40%" src="/images/ml_31.jpg" alt="">

<h2 id="应用到支持向量机上"><a href="#应用到支持向量机上" class="headerlink" title="应用到支持向量机上"></a>应用到支持向量机上</h2><h3 id="选取标记向量"><a href="#选取标记向量" class="headerlink" title="选取标记向量"></a>选取标记向量</h3><p>在实际应用中，将每个样本作为标记向量。<br>假设有样本$x^{(1)},x^{(2)},…,x^{(m)}$，同样的，将每个样本都定义为标记点，$l^{(1)},l^{(2)},…,l^{(m)}$，即：$x^{(1)}=l^{(1)},x^{(2)}=l^{(2)},…,x^{(m)}=l^{(m)}$。</p>
<p>对于某一个样本$(x^{(i)},y^{(i)})$来说：<br>$f_1^{(i)}$ = similarity$(x^{(i)}, l^{(1)})$<br>$f_2^{(i)}$ = similarity$(x^{(i)}, l^{(2)})$<br>…<br>$f_i^{(i)}$ = similarity$(x^{(i)}, l^{(i)})=1$<br>…<br>$f_m^{(i)}$ = similarity$(x^{(i)}, l^{(m)})$</p>
<p><em>PS：在这其中，第$i$个样本向量和第$i$个标记向量是同一个，所以值为1。</em></p>
<p>对于某一个样本的新的特征向量$f^{(i)}=\left[ \begin{matrix} f^{(i)}_0 \\ f^{(i)}_1 \\ f^{(i)}_2 \\ … \\ f^{(i)}_m \end{matrix}\right]$，同样的$f^{(i)}_0$始终为1，$f$是一个m+1的向量。</p>
<p>当使用新的特征值后，当$\theta^Tf \geq 0$时，即可预测输出值为1。</p>
<p>支持向量机的代价函数为：<br>$$ J(\theta)=-C \sum_{i=1}^m [y^{(i)} cost_1(\theta^Tx) + (1-y^{(i)}) cost_0(\theta^Tx)] + \frac{1}{2} \sum_{j=1}^n \theta_j^2 $$</p>
<p>将新的特征值替换到支持向量机的代价函数中去：</p>
<p>$$ J(\theta)=-C \sum_{i=1}^m [y^{(i)} cost_1(\theta^Tf^{(i)}) + (1-y^{(i)}) cost_0(\theta^Tf^{(i)})] + \frac{1}{2} \sum_{j=1}^m \theta_j^2 $$</p>
<p>可以看到将$x^{(i)}$替换成了$f^{(i)}$，$\sum_{j=1}^m \theta_j^2$中是统计从1到m的参数了，因为，新的特征向量是m+1维向量，而且$\theta_0$不用修正。</p>
<p>核函数也可以用到逻辑回归上，但是这样计算成本会很高，速度会慢许多。而在SVM上，有许多针对核函数的优化方法，使得核函数在SVM上运行良好。</p>
<h2 id="SVM使用事项"><a href="#SVM使用事项" class="headerlink" title="SVM使用事项"></a>SVM使用事项</h2><p>在使用SVM时一般都是使用第三方包提供的SVM优化算法，我们仅需提供：</p>
<ul>
<li>参数C</li>
<li>选择核函数</li>
</ul>
<h3 id="参数C"><a href="#参数C" class="headerlink" title="参数C"></a>参数C</h3><p>参数C可以看作$\frac{1}{\lambda}$，与$\lambda$相关的：</p>
<ul>
<li>C过大时，会导致高方差，过拟合的问题；</li>
<li>C过小时，会导致高偏差，欠拟合的问题。</li>
</ul>
<p>因此需要选取折中的C值，可以通过选取多个C值，然后在交叉验证集上简直多个C值的误差，选择最小的。</p>
<h3 id="核函数选择"><a href="#核函数选择" class="headerlink" title="核函数选择"></a>核函数选择</h3><p>在核函数的选择上，一般有两种，一个是不用核函数，一个是高斯核函数。</p>
<p>不用核函数也称为线性核函数。它和逻辑回归的算法效果类似。当训练集有大量的特征值，但是样本数量不是太多时，这时拟合一个线性的边界条件会有比较好的效果，也即一般会不使用核函数或使用线性核函数。 </p>
<p>高斯核函数 则需要去选择$\sigma^2$</p>
<p><strong>参数$\sigma^2$</strong></p>
<ul>
<li>当$\sigma^2$过小时，$f$核函数的变化速度会很剧烈，会导致高方差的现象；</li>
<li>当$\sigma^2$过大时，$f$核函数的变化速度会很平缓，会导致高偏差的现象。</li>
</ul>
<p>当训练集的特征值不是特别多，而且有大量的样本数量时可以选择高斯核函数。</p>
<p>当使用高斯核函数时，一个很重要的操作就是特征值的缩放，因为计算相似度时，会计算$|| x-l^{(i)} ||^2$，当每个特征值的取值范围相差很大时，求得的范数会受范围大的特征值的影响。为了避免这种情况，需要缩放到相近的范围内。</p>
<h2 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h2><p>在处理多元分类问题时，与逻辑分类和神经网络类似，也是训练多个SVM训练器，然后比较取性能最好的一个。<br>更方便的方式是使用第三方的库函数来实现多元分类问题。 </p>
<h2 id="逻辑回归和SVM"><a href="#逻辑回归和SVM" class="headerlink" title="逻辑回归和SVM"></a>逻辑回归和SVM</h2><p>定义：n = 样本的特征值数量，m = 样本的数量。</p>
<ul>
<li><p>当n相对于m来时很大时，比如n=10000，m=1000时，这时选择逻辑回归或者不使用核函数的SVM；</p>
</li>
<li><p>当n比较小，m中等大小，比如n=1000，m=10000时，选择SVM（使用高斯核函数）的效果会比较好； </p>
</li>
<li><p>当n比较小，m非常大时，比如n=1000，m=50000+时，这时通常手动添加更多的特征值，然后使用逻辑回归或者不使用核函数的SVM来处理。</p>
</li>
</ul>
<p>而神经网络算法，通常都会比这两者来的慢，且需要良好的设计才能取得较好的效果。而且使用SVM时不用担心遇到局部最优的问题。</p>
</div><div class="tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a href="/tags/SVM/">SVM</a></div><div class="post-nav"><a class="pre" href="/2020/02/06/tech/machine_learning/k_means_intro.html">K均值算法介绍</a><a class="next" href="/2020/01/31/tech/machine_learning/svm_intro.html">支持向量机算法（SVM）介绍</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/%E9%A9%AC%E6%8B%89%E6%9D%BE/" style="font-size: 10px;">马拉松</a> <a href="/tags/HTTP/" style="font-size: 10px;">HTTP</a> <a href="/tags/mysql/" style="font-size: 11.25px;">mysql</a> <a href="/tags/javascript/" style="font-size: 18.75px;">javascript</a> <a href="/tags/bootstrap/" style="font-size: 10px;">bootstrap</a> <a href="/tags/HTML/" style="font-size: 11.25px;">HTML</a> <a href="/tags/vue/" style="font-size: 10px;">vue</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">机器学习</a> <a href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 16.25px;">监督学习</a> <a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" style="font-size: 12.5px;">逻辑回归</a> <a href="/tags/%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">非监督学习</a> <a href="/tags/%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96/" style="font-size: 12.5px;">算法优化</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 13.75px;">线性回归</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 12.5px;">神经网络</a> <a href="/tags/SVM/" style="font-size: 11.25px;">SVM</a> <a href="/tags/PHP/" style="font-size: 10px;">PHP</a> <a href="/tags/python/" style="font-size: 17.5px;">python</a> <a href="/tags/pandas/" style="font-size: 13.75px;">pandas</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 12.5px;">数据结构</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/05/24/tech/python/structure/str-search-and-kmp.html">字符串朴素匹配算法和KMP算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/03/tech/python/structure/josephus-solve.html">约瑟夫（Josephos）问题以及解法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/31/tech/python/structure/link-intro.html">链表介绍及python的实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/09/tech/machine_learning/learn_large_datasets.html">在大数据下应用机器学习算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/tech/machine_learning/mini_batch_gradient_descent.html">小批量梯度下降算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/tech/machine_learning/stochastic_gradient_descent.html">随机梯度下降算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/08/tech/machine_learning/recommender_system.html">推荐系统和协同过滤算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/tech/machine_learning/anomaly_detection.html">异常检测（Anomaly Detection）</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/06/tech/machine_learning/dimensionality_reduction.html">PCA降维算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/06/tech/machine_learning/k_means_intro.html">K均值算法介绍</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.jianshu.com/u/f133ca80001f" title="爱吃鱼的夏侯莲子" target="_blank">爱吃鱼的夏侯莲子</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">DeepCode</a>&nbsp;|&nbsp;<a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener">苏ICP备20021898号-1</a>&nbsp;|&nbsp;<img class="nofancybox" src="../images/beian/icon.png" style="margin-bottom: -4px;"/><a href="http://www.beian.gov.cn/" target="_blank" rel="noopener">苏公网安备 32059002003042号</a><div class="ss"> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>