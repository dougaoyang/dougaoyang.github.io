---
layout: post
title: 小批量梯度下降算法
date: 2020-02-08 18:00
categories:
- 技术
tags:
- 机器学习
description: 批量梯度下降是每一次迭代中对所有样本求和后求梯度项，随机梯度下降是对每一个样本求梯度项，小批量梯度下降介于两者之间。
mathjax: true
---

批量梯度下降是每一次迭代中对所有样本求和后求梯度项，随机梯度下降是对每一个样本求梯度项，小批量梯度下降介于两者之间。

小批量梯度下降取的样本数一般在2-100之间：
例如样本总数m=1000，每次取样本b=10:

重复 {
 　　for i = 1,11,21,...,991 {
　　　　$ \theta_j:=\theta_j−\alpha \frac{1}{10}\sum_{k=i}^{i+9}(h_\theta(x^{(k)})-y^{(k)})x_j^{(k)} $
　　}
}

一次计算多个样本的优点是，多个样本能够以矢量化的方式进行，能够多个样本并行化处理，又不至于对所有样本求和那个耗费计算成本。
在某些情况下，小批量梯度下降的速度会优于随机梯度下降，但是在选择小批量样本数量b时会耗费一些时间。
